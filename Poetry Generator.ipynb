{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up list of common misconceptions ...\n",
      "Looking up cause ...\n",
      "Looking up cause ...\n",
      "Looking up Anderston railway station ...\n",
      "\n",
      "A Fowler's echoes this sentiment: “the\n",
      "== “healthy” has only recently been\n",
      "Cause passage to sound weak and, in some\n",
      "Dictionary”. Oxford university press. Isbn\n",
      "\n",
      "Object and accepts simultaneous cause\n",
      "Object and accepts simultaneous cause\n",
      "Object and accepts simultaneous cause may alternatively cause\n",
      "\n",
      "Following of causality is a cause\n",
      "A metaphysical question about cause, informal fallacies where a cause\n",
      "Referring efficient cause, which imparts the first three: 1. “The cause\n",
      "\n",
      "1tph cumbernauld via Hamilton 1tph\n",
      "Platform stopping place, past and present (1st\n",
      "(1st spark ford: Patrick Stephens ltd. Isbn 978-1-85260-086-0. Oclc\n",
      "Subsequently by the Glasgow central railway which\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "import language_check\n",
    "import string\n",
    "import re\n",
    "import wikipedia\n",
    "\n",
    "class Markov(object):\n",
    "    def __init__(self, string):\n",
    "        self.cache = {}\n",
    "        self.words = string.split()\n",
    "        #self.words = re.split(' |\\+|\\n|“|”|\\.|\\,|\\'|=',string)\n",
    "        self.words.reverse()\n",
    "        self.words = [x.lower() for x in self.words]\n",
    "        self.wordchoices = list(set(self.words))\n",
    "        self.word_size = len(self.words)\n",
    "        self.database()\n",
    "\t\t\n",
    "    def triples(self):\n",
    "\t\t#Generates triples from the given data string. So if our string were \"What a lovely day\", we'd generate (What, a, lovely) and then (a, lovely, day).\n",
    "        if len(self.words) < 3:\n",
    "            return\n",
    "        for i in range(len(self.words) - 2):\n",
    "            yield (self.words[i], self.words[i+1], self.words[i+2])\n",
    "\t\t\t\n",
    "    def database(self):\n",
    "        for w1, w2, w3 in self.triples():\n",
    "            key = (w1, w2)\n",
    "            if key in self.cache:\n",
    "                self.cache[key].append(w3)\n",
    "            else:\n",
    "                self.cache[key] = [w3]\n",
    "\t\t\t\t\n",
    "    def generate_markov_text(self, size=-1, seed_word=''):\n",
    "        #size of -1 means complete sentence\n",
    "        seed_word=seed_word.lower()\n",
    "        seed = random.randint(0, self.word_size-3)\n",
    "        try:\n",
    "            next_word=self.words[random.choice([i for i,x in enumerate(self.words) if x==seed_word])+1]\n",
    "        except:\n",
    "            seed_word, next_word = self.words[seed], self.words[seed+1]\n",
    "        w1, w2 = seed_word, next_word\n",
    "        gen_words = []\n",
    "        if size!=-1:\n",
    "            for i in range(size):\n",
    "                gen_words.append(w1)\n",
    "                w1, w2 = w2, random.choice(self.cache[(w1, w2)])\n",
    "                #print(self.cache[(w1, w2)])\n",
    "        else:\n",
    "            while True:\n",
    "                gen_words.append(w1)\n",
    "                w1, w2 = w2, random.choice(self.cache[(w1, w2)])\n",
    "                #print(self.cache[(w1, w2)])\n",
    "                if((w2[-1]=='.')|(w2[-1]=='!')|(w2[-1]=='?')):\n",
    "                    break\n",
    "        gen_words.append(w2)\n",
    "        return ' '.join(gen_words).capitalize()\n",
    "    \n",
    "    def generate_markov_text_syl(self, size=10, seed_word=''):\n",
    "        #size of -1 means complete sentence\n",
    "        seed_word=seed_word.lower()\n",
    "        try:\n",
    "            wordpool=[i_markov_text for i_markov_text,x in enumerate(self.words) if x==seed_word]\n",
    "            if(len(wordpool)>0):\n",
    "                next_word=self.words[random.choice([i_markov_text for i_markov_text,x in enumerate(self.words) if x==seed_word])+1]\n",
    "            else:\n",
    "                seed = random.randint(0, self.word_size-3)\n",
    "                seed_word, next_word = self.words[seed], self.words[seed+1]\n",
    "        except:\n",
    "            seed = random.randint(0, self.word_size-3)\n",
    "            seed_word, next_word = self.words[seed], self.words[seed+1]\n",
    "        gen_words = []\n",
    "        if size!=-1:\n",
    "            while True:\n",
    "                gen_words.append(seed_word)\n",
    "                seed_word, next_word = next_word, random.choice(self.cache[(seed_word, next_word)])\n",
    "                if(syllablesPhrase(' '.join(gen_words))>=size):\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                gen_words.append(seed_word)\n",
    "                seed_word, next_word = next_word, random.choice(self.cache[(seed_word, next_word)])\n",
    "                #print(self.cache[(w1, w2)])\n",
    "                if((next_word[-1]=='.')|(next_word[-1]=='!')|(next_word[-1]=='?')):\n",
    "                    break\n",
    "        gen_words.append(next_word)\n",
    "        return ' '.join(reversed(gen_words)).capitalize()\n",
    "        \n",
    "def generateStanza2(seed,file1,lines=4,line_length=10,counting=0):\n",
    "    #alternating lines from two corpuses (not corpii)\n",
    "    stanza=''\n",
    "    #counting determines if count is by word or by syllable (0= by syllable)\n",
    "    for item in range(lines):\n",
    "        if(seed!=''):\n",
    "            sentence=file1.generate_markov_text_syl(size=line_length,seed_word=str(seed))\n",
    "        else:\n",
    "            sentence=file1.generate_markov_text_syl(size=line_length)\n",
    "        stanza=stanza+sentence+'\\n'\n",
    "        try:\n",
    "            rhymingWords=list(rhyme(sentence.split()[-1].translate(str.maketrans('','',string.punctuation)),1))\n",
    "            rhymingWords=[wordchoice for wordchoice in rhymingWords if wordchoice in file1.wordchoices]\n",
    "        except:\n",
    "            seed=random.choice(rhymingWords)\n",
    "    return stanza\n",
    "\n",
    "def syllablesPhrase(phrase):\n",
    "    count=0\n",
    "    for word in phrase.split():\n",
    "        vowels = 'aeiouy'\n",
    "        word = word.lower().strip(\".:;?!\")\n",
    "        if word[0] in vowels:\n",
    "            count +=1\n",
    "        for index in range(1,len(word)):\n",
    "            if word[index] in vowels and word[index-1] not in vowels:\n",
    "                count +=1\n",
    "        if word.endswith('e'):\n",
    "            count -= 1\n",
    "        if word.endswith('le'):\n",
    "            count+=1\n",
    "        if count == 0:\n",
    "            count +=1\n",
    "    return count\n",
    "\n",
    "def rhyme(inp, level):\n",
    "    entries = nltk.corpus.cmudict.entries()\n",
    "    syllables = [(word, syl) for word, syl in entries if word == inp]\n",
    "    rhymes = []\n",
    "    for (word, syllable) in syllables:\n",
    "        rhymes += [word for word, pron in entries if pron[-level:] == syllable[-level:]]\n",
    "    return set(rhymes)\n",
    "\n",
    "def fixCapitalization(string,proper_nouns=False):\n",
    "    string=string.replace(' i ',' I ')\n",
    "    string=string.replace(' i\\'',' I\\'')\n",
    "    if(proper_nouns==True):\n",
    "        #use named entity recognition to identify proper nouns\n",
    "        print('')\n",
    "    return string\n",
    "\n",
    "story=''\n",
    "seed='list of common misconceptions'\n",
    "numLines=5\n",
    "for i in range(1,numLines):\n",
    "    print('Looking up',seed,'...')\n",
    "    model=Markov(wikipedia.page(seed).content)\n",
    "    newStanza=generateStanza2(seed,model,lines=4,line_length=8)\n",
    "    #print(newStanza)\n",
    "    story=story+'\\n'+newStanza\n",
    "    storyWords=re.split(' |\\+|\\n|“|”|\\.|\\,|\\'|=',story.lower().translate(string.punctuation))\n",
    "    storyWords=[word for word in storyWords if word!='']\n",
    "    tempSeed=random.choice(storyWords)\n",
    "    try:\n",
    "        wikipedia.summary(tempSeed)\n",
    "        seed=tempSeed\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        storyWords=[word for word in e.options if not '(disambiguation)' in word]\n",
    "        seed=random.choice(storyWords)\n",
    "\n",
    "story=fixCapitalization(story)\n",
    "story=language_check.correct(story,language_check.LanguageTool('en-US').check(story))\n",
    "\n",
    "print(story)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
